{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.insert(0,\"../\")\n",
    "from resnet18 import Residual\n",
    "import torch as t\n",
    "net = Residual(3,3,False,1)\n",
    "x = t.randn((1,3,24,24))\n",
    "\n",
    "y = net.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 24, 24]), torch.Size([1, 3, 24, 24]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Residual(3,6,True,1)\n",
    "x = t.randn((1,3,24,24))\n",
    "\n",
    "y = net.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 24, 24]), torch.Size([1, 6, 24, 24]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential output shape: \t torch.Size([1, 64, 56, 56])\n",
      "Sequential output shape: \t torch.Size([1, 64, 56, 56])\n",
      "Sequential output shape: \t torch.Size([1, 128, 28, 28])\n",
      "Sequential output shape: \t torch.Size([1, 256, 14, 14])\n",
      "Sequential output shape: \t torch.Size([1, 512, 7, 7])\n",
      "AdaptiveMaxPool2d output shape: \t torch.Size([1, 512, 1, 1])\n",
      "Flatten output shape: \t torch.Size([1, 512])\n",
      "Linear output shape: \t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "from resnet18 import Resnet18\n",
    "x = t.rand(size=(1, 1, 224, 224))\n",
    "net = Resnet18().net\n",
    "for layer in net:\n",
    "    x = layer(x)\n",
    "    print(layer.__class__.__name__,\"output shape: \\t\",x.shape)\n",
    "x.sum().backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.weight\n",
      "0.0.bias\n",
      "0.1.weight\n",
      "0.1.bias\n",
      "0.1.running_mean\n",
      "0.1.running_var\n",
      "0.1.num_batches_tracked\n",
      "1.0.features.0.weight\n",
      "1.0.features.0.bias\n",
      "1.0.features.1.weight\n",
      "1.0.features.1.bias\n",
      "1.0.features.1.running_mean\n",
      "1.0.features.1.running_var\n",
      "1.0.features.1.num_batches_tracked\n",
      "1.0.features.3.weight\n",
      "1.0.features.3.bias\n",
      "1.0.features.4.weight\n",
      "1.0.features.4.bias\n",
      "1.0.features.4.running_mean\n",
      "1.0.features.4.running_var\n",
      "1.0.features.4.num_batches_tracked\n",
      "1.1.features.0.weight\n",
      "1.1.features.0.bias\n",
      "1.1.features.1.weight\n",
      "1.1.features.1.bias\n",
      "1.1.features.1.running_mean\n",
      "1.1.features.1.running_var\n",
      "1.1.features.1.num_batches_tracked\n",
      "1.1.features.3.weight\n",
      "1.1.features.3.bias\n",
      "1.1.features.4.weight\n",
      "1.1.features.4.bias\n",
      "1.1.features.4.running_mean\n",
      "1.1.features.4.running_var\n",
      "1.1.features.4.num_batches_tracked\n",
      "2.0.features.0.weight\n",
      "2.0.features.0.bias\n",
      "2.0.features.1.weight\n",
      "2.0.features.1.bias\n",
      "2.0.features.1.running_mean\n",
      "2.0.features.1.running_var\n",
      "2.0.features.1.num_batches_tracked\n",
      "2.0.features.3.weight\n",
      "2.0.features.3.bias\n",
      "2.0.features.4.weight\n",
      "2.0.features.4.bias\n",
      "2.0.features.4.running_mean\n",
      "2.0.features.4.running_var\n",
      "2.0.features.4.num_batches_tracked\n",
      "2.0.adj_conv.weight\n",
      "2.0.adj_conv.bias\n",
      "2.1.features.0.weight\n",
      "2.1.features.0.bias\n",
      "2.1.features.1.weight\n",
      "2.1.features.1.bias\n",
      "2.1.features.1.running_mean\n",
      "2.1.features.1.running_var\n",
      "2.1.features.1.num_batches_tracked\n",
      "2.1.features.3.weight\n",
      "2.1.features.3.bias\n",
      "2.1.features.4.weight\n",
      "2.1.features.4.bias\n",
      "2.1.features.4.running_mean\n",
      "2.1.features.4.running_var\n",
      "2.1.features.4.num_batches_tracked\n",
      "3.0.features.0.weight\n",
      "3.0.features.0.bias\n",
      "3.0.features.1.weight\n",
      "3.0.features.1.bias\n",
      "3.0.features.1.running_mean\n",
      "3.0.features.1.running_var\n",
      "3.0.features.1.num_batches_tracked\n",
      "3.0.features.3.weight\n",
      "3.0.features.3.bias\n",
      "3.0.features.4.weight\n",
      "3.0.features.4.bias\n",
      "3.0.features.4.running_mean\n",
      "3.0.features.4.running_var\n",
      "3.0.features.4.num_batches_tracked\n",
      "3.0.adj_conv.weight\n",
      "3.0.adj_conv.bias\n",
      "3.1.features.0.weight\n",
      "3.1.features.0.bias\n",
      "3.1.features.1.weight\n",
      "3.1.features.1.bias\n",
      "3.1.features.1.running_mean\n",
      "3.1.features.1.running_var\n",
      "3.1.features.1.num_batches_tracked\n",
      "3.1.features.3.weight\n",
      "3.1.features.3.bias\n",
      "3.1.features.4.weight\n",
      "3.1.features.4.bias\n",
      "3.1.features.4.running_mean\n",
      "3.1.features.4.running_var\n",
      "3.1.features.4.num_batches_tracked\n",
      "4.0.features.0.weight\n",
      "4.0.features.0.bias\n",
      "4.0.features.1.weight\n",
      "4.0.features.1.bias\n",
      "4.0.features.1.running_mean\n",
      "4.0.features.1.running_var\n",
      "4.0.features.1.num_batches_tracked\n",
      "4.0.features.3.weight\n",
      "4.0.features.3.bias\n",
      "4.0.features.4.weight\n",
      "4.0.features.4.bias\n",
      "4.0.features.4.running_mean\n",
      "4.0.features.4.running_var\n",
      "4.0.features.4.num_batches_tracked\n",
      "4.0.adj_conv.weight\n",
      "4.0.adj_conv.bias\n",
      "4.1.features.0.weight\n",
      "4.1.features.0.bias\n",
      "4.1.features.1.weight\n",
      "4.1.features.1.bias\n",
      "4.1.features.1.running_mean\n",
      "4.1.features.1.running_var\n",
      "4.1.features.1.num_batches_tracked\n",
      "4.1.features.3.weight\n",
      "4.1.features.3.bias\n",
      "4.1.features.4.weight\n",
      "4.1.features.4.bias\n",
      "4.1.features.4.running_mean\n",
      "4.1.features.4.running_var\n",
      "4.1.features.4.num_batches_tracked\n",
      "7.weight\n",
      "7.bias\n"
     ]
    }
   ],
   "source": [
    "for key in net.state_dict():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('4.0.features.1.weight', tensor(22.6274)),\n",
       " ('4.0.features.4.weight', tensor(22.6274)),\n",
       " ('4.1.features.1.weight', tensor(22.6274)),\n",
       " ('4.1.features.4.weight', tensor(22.6274)),\n",
       " ('3.0.features.1.weight', tensor(16.)),\n",
       " ('3.0.features.4.weight', tensor(16.)),\n",
       " ('3.1.features.1.weight', tensor(16.)),\n",
       " ('3.1.features.4.weight', tensor(16.)),\n",
       " ('4.0.adj_conv.weight', tensor(13.0821)),\n",
       " ('4.0.features.3.weight', tensor(13.0645)),\n",
       " ('4.1.features.0.weight', tensor(13.0641)),\n",
       " ('4.0.features.0.weight', tensor(13.0572)),\n",
       " ('4.1.features.3.weight', tensor(13.0520)),\n",
       " ('2.0.features.1.weight', tensor(11.3137)),\n",
       " ('2.0.features.4.weight', tensor(11.3137)),\n",
       " ('2.1.features.1.weight', tensor(11.3137)),\n",
       " ('2.1.features.4.weight', tensor(11.3137)),\n",
       " ('3.1.features.0.weight', tensor(9.2427)),\n",
       " ('3.0.adj_conv.weight', tensor(9.2416)),\n",
       " ('3.0.features.3.weight', tensor(9.2410)),\n",
       " ('3.1.features.3.weight', tensor(9.2382)),\n",
       " ('3.0.features.0.weight', tensor(9.2345)),\n",
       " ('0.1.weight', tensor(8.)),\n",
       " ('1.0.features.1.weight', tensor(8.)),\n",
       " ('1.0.features.4.weight', tensor(8.)),\n",
       " ('1.1.features.1.weight', tensor(8.)),\n",
       " ('1.1.features.4.weight', tensor(8.)),\n",
       " ('2.0.features.0.weight', tensor(6.5486)),\n",
       " ('2.1.features.0.weight', tensor(6.5367)),\n",
       " ('2.1.features.3.weight', tensor(6.5336)),\n",
       " ('2.0.features.3.weight', tensor(6.5269)),\n",
       " ('2.0.adj_conv.weight', tensor(6.5233)),\n",
       " ('0.0.weight', tensor(4.6642)),\n",
       " ('1.1.features.3.weight', tensor(4.6296)),\n",
       " ('1.0.features.3.weight', tensor(4.6149)),\n",
       " ('1.1.features.0.weight', tensor(4.6146)),\n",
       " ('1.0.features.0.weight', tensor(4.6125)),\n",
       " ('7.weight', tensor(1.8286))]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch as t\n",
    "weight_norm = {}\n",
    "with t.no_grad():\n",
    "    for name, param in net.named_parameters():\n",
    "        \n",
    "        if \"weight\" in name:\n",
    "            weight_norm[name] = t.norm(param)\n",
    "weight_norm = sorted(weight_norm.items(),key=lambda x: x[1],reverse=True)\n",
    "weight_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.0.features.0.weight',\n",
       " '1.0.features.3.weight',\n",
       " '2.0.features.3.weight',\n",
       " '3.0.features.3.weight',\n",
       " '2.1.features.0.weight',\n",
       " '1.1.features.0.weight',\n",
       " '2.0.features.0.weight',\n",
       " '4.0.features.3.weight',\n",
       " '3.1.features.0.weight',\n",
       " '3.0.features.0.weight',\n",
       " '2.1.features.3.weight',\n",
       " '4.0.features.0.weight',\n",
       " '1.1.features.3.weight',\n",
       " '3.1.features.3.weight',\n",
       " '4.1.features.0.weight',\n",
       " '0.0.weight',\n",
       " '7.weight',\n",
       " '4.1.features.3.weight',\n",
       " '2.0.adj_conv.weight',\n",
       " '3.0.adj_conv.weight',\n",
       " '4.0.adj_conv.weight',\n",
       " '0.1.weight',\n",
       " '1.0.features.1.weight',\n",
       " '1.0.features.4.weight',\n",
       " '2.0.features.1.weight',\n",
       " '1.1.features.1.weight',\n",
       " '1.1.features.4.weight',\n",
       " '2.0.features.4.weight',\n",
       " '2.1.features.1.weight',\n",
       " '3.0.features.4.weight',\n",
       " '2.1.features.4.weight',\n",
       " '3.0.features.1.weight',\n",
       " '4.0.features.4.weight',\n",
       " '3.1.features.1.weight',\n",
       " '4.1.features.4.weight',\n",
       " '4.0.features.1.weight',\n",
       " '3.1.features.4.weight',\n",
       " '4.1.features.1.weight']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_norm = {}\n",
    "for name, param in net.named_parameters():\n",
    "    if \"weight\" in name:\n",
    "        if param.grad is None:\n",
    "            print(name,\"--None\")\n",
    "        else:\n",
    "            grad_norm[name] = t.norm(param.grad)\n",
    "\n",
    "grad_norm = sorted(grad_norm.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "l =[a[0] for a in grad_norm]\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): Residual(\n",
       "      (features): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Residual(\n",
       "      (features): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): Residual(\n",
       "      (features): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (adj_conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "    )\n",
       "    (1): Residual(\n",
       "      (features): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (3): Sequential(\n",
       "    (0): Residual(\n",
       "      (features): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (adj_conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "    )\n",
       "    (1): Residual(\n",
       "      (features): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (4): Sequential(\n",
       "    (0): Residual(\n",
       "      (features): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (adj_conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
       "    )\n",
       "    (1): Residual(\n",
       "      (features): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (5): AdaptiveMaxPool2d(output_size=(1, 1))\n",
       "  (6): Flatten(start_dim=1, end_dim=-1)\n",
       "  (7): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    pass\n",
    "    # have not implemented yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(net.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[114., 114., 114.],\n",
       "          [114., 114., 114.],\n",
       "          [114., 114., 114.]],\n",
       "\n",
       "         [[114., 114., 114.],\n",
       "          [114., 114., 114.],\n",
       "          [114., 114., 114.]],\n",
       "\n",
       "         [[114., 114., 114.],\n",
       "          [114., 114., 114.],\n",
       "          [114., 114., 114.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[114., 114., 114.],\n",
       "          [114., 114., 114.],\n",
       "          [114., 114., 114.]],\n",
       "\n",
       "         [[114., 114., 114.],\n",
       "          [114., 114., 114.],\n",
       "          [114., 114., 114.]],\n",
       "\n",
       "         [[114., 114., 114.],\n",
       "          [114., 114., 114.],\n",
       "          [114., 114., 114.]]],\n",
       "\n",
       "\n",
       "        [[[114., 114., 114.],\n",
       "          [114., 114., 114.],\n",
       "          [114., 114., 114.]],\n",
       "\n",
       "         [[114., 114., 114.],\n",
       "          [114., 114., 114.],\n",
       "          [114., 114., 114.]],\n",
       "\n",
       "         [[114., 114., 114.],\n",
       "          [114., 114., 114.],\n",
       "          [114., 114., 114.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[114., 114., 114.],\n",
       "          [114., 114., 114.],\n",
       "          [114., 114., 114.]],\n",
       "\n",
       "         [[114., 114., 114.],\n",
       "          [114., 114., 114.],\n",
       "          [114., 114., 114.]],\n",
       "\n",
       "         [[114., 114., 114.],\n",
       "          [114., 114., 114.],\n",
       "          [114., 114., 114.]]],\n",
       "\n",
       "\n",
       "        [[[114., 114., 114.],\n",
       "          [114., 114., 114.],\n",
       "          [114., 114., 114.]],\n",
       "\n",
       "         [[114., 114., 114.],\n",
       "          [114., 114., 114.],\n",
       "          [114., 114., 114.]],\n",
       "\n",
       "         [[114., 114., 114.],\n",
       "          [114., 114., 114.],\n",
       "          [114., 114., 114.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[114., 114., 114.],\n",
       "          [114., 114., 114.],\n",
       "          [114., 114., 114.]],\n",
       "\n",
       "         [[114., 114., 114.],\n",
       "          [114., 114., 114.],\n",
       "          [114., 114., 114.]],\n",
       "\n",
       "         [[114., 114., 114.],\n",
       "          [114., 114., 114.],\n",
       "          [114., 114., 114.]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[114., 114., 114.],\n",
       "          [114., 114., 114.],\n",
       "          [114., 114., 114.]],\n",
       "\n",
       "         [[114., 114., 114.],\n",
       "          [114., 114., 114.],\n",
       "          [114., 114., 114.]],\n",
       "\n",
       "         [[114., 114., 114.],\n",
       "          [114., 114., 114.],\n",
       "          [114., 114., 114.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[114., 114., 114.],\n",
       "          [114., 114., 114.],\n",
       "          [114., 114., 114.]],\n",
       "\n",
       "         [[114., 114., 114.],\n",
       "          [114., 114., 114.],\n",
       "          [114., 114., 114.]],\n",
       "\n",
       "         [[114., 114., 114.],\n",
       "          [114., 114., 114.],\n",
       "          [114., 114., 114.]]],\n",
       "\n",
       "\n",
       "        [[[114., 114., 114.],\n",
       "          [114., 114., 114.],\n",
       "          [114., 114., 114.]],\n",
       "\n",
       "         [[114., 114., 114.],\n",
       "          [114., 114., 114.],\n",
       "          [114., 114., 114.]],\n",
       "\n",
       "         [[114., 114., 114.],\n",
       "          [114., 114., 114.],\n",
       "          [114., 114., 114.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[114., 114., 114.],\n",
       "          [114., 114., 114.],\n",
       "          [114., 114., 114.]],\n",
       "\n",
       "         [[114., 114., 114.],\n",
       "          [114., 114., 114.],\n",
       "          [114., 114., 114.]],\n",
       "\n",
       "         [[114., 114., 114.],\n",
       "          [114., 114., 114.],\n",
       "          [114., 114., 114.]]],\n",
       "\n",
       "\n",
       "        [[[114., 114., 114.],\n",
       "          [114., 114., 114.],\n",
       "          [114., 114., 114.]],\n",
       "\n",
       "         [[114., 114., 114.],\n",
       "          [114., 114., 114.],\n",
       "          [114., 114., 114.]],\n",
       "\n",
       "         [[114., 114., 114.],\n",
       "          [114., 114., 114.],\n",
       "          [114., 114., 114.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[114., 114., 114.],\n",
       "          [114., 114., 114.],\n",
       "          [114., 114., 114.]],\n",
       "\n",
       "         [[114., 114., 114.],\n",
       "          [114., 114., 114.],\n",
       "          [114., 114., 114.]],\n",
       "\n",
       "         [[114., 114., 114.],\n",
       "          [114., 114., 114.],\n",
       "          [114., 114., 114.]]]], requires_grad=True)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(net.named_parameters())[4][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dit = {\"1.0.features.0.weight\":t.ones((64, 64, 3, 3))*114}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['0.0.weight', '0.0.bias', '0.1.weight', '0.1.bias', '0.1.running_mean', '0.1.running_var', '1.0.features.0.bias', '1.0.features.1.weight', '1.0.features.1.bias', '1.0.features.1.running_mean', '1.0.features.1.running_var', '1.0.features.3.weight', '1.0.features.3.bias', '1.0.features.4.weight', '1.0.features.4.bias', '1.0.features.4.running_mean', '1.0.features.4.running_var', '1.1.features.0.weight', '1.1.features.0.bias', '1.1.features.1.weight', '1.1.features.1.bias', '1.1.features.1.running_mean', '1.1.features.1.running_var', '1.1.features.3.weight', '1.1.features.3.bias', '1.1.features.4.weight', '1.1.features.4.bias', '1.1.features.4.running_mean', '1.1.features.4.running_var', '2.0.features.0.weight', '2.0.features.0.bias', '2.0.features.1.weight', '2.0.features.1.bias', '2.0.features.1.running_mean', '2.0.features.1.running_var', '2.0.features.3.weight', '2.0.features.3.bias', '2.0.features.4.weight', '2.0.features.4.bias', '2.0.features.4.running_mean', '2.0.features.4.running_var', '2.0.adj_conv.weight', '2.0.adj_conv.bias', '2.1.features.0.weight', '2.1.features.0.bias', '2.1.features.1.weight', '2.1.features.1.bias', '2.1.features.1.running_mean', '2.1.features.1.running_var', '2.1.features.3.weight', '2.1.features.3.bias', '2.1.features.4.weight', '2.1.features.4.bias', '2.1.features.4.running_mean', '2.1.features.4.running_var', '3.0.features.0.weight', '3.0.features.0.bias', '3.0.features.1.weight', '3.0.features.1.bias', '3.0.features.1.running_mean', '3.0.features.1.running_var', '3.0.features.3.weight', '3.0.features.3.bias', '3.0.features.4.weight', '3.0.features.4.bias', '3.0.features.4.running_mean', '3.0.features.4.running_var', '3.0.adj_conv.weight', '3.0.adj_conv.bias', '3.1.features.0.weight', '3.1.features.0.bias', '3.1.features.1.weight', '3.1.features.1.bias', '3.1.features.1.running_mean', '3.1.features.1.running_var', '3.1.features.3.weight', '3.1.features.3.bias', '3.1.features.4.weight', '3.1.features.4.bias', '3.1.features.4.running_mean', '3.1.features.4.running_var', '4.0.features.0.weight', '4.0.features.0.bias', '4.0.features.1.weight', '4.0.features.1.bias', '4.0.features.1.running_mean', '4.0.features.1.running_var', '4.0.features.3.weight', '4.0.features.3.bias', '4.0.features.4.weight', '4.0.features.4.bias', '4.0.features.4.running_mean', '4.0.features.4.running_var', '4.0.adj_conv.weight', '4.0.adj_conv.bias', '4.1.features.0.weight', '4.1.features.0.bias', '4.1.features.1.weight', '4.1.features.1.bias', '4.1.features.1.running_mean', '4.1.features.1.running_var', '4.1.features.3.weight', '4.1.features.3.bias', '4.1.features.4.weight', '4.1.features.4.bias', '4.1.features.4.running_mean', '4.1.features.4.running_var', '7.weight', '7.bias'], unexpected_keys=[])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(dit,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'nvidia-smi' �����ڲ����ⲿ���Ҳ���ǿ����еĳ���\n",
      "���������ļ���\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m net \u001b[39m=\u001b[39mnet\u001b[39m.\u001b[39;49mcuda()\n\u001b[0;32m      2\u001b[0m tensortensor \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39mrandn((\u001b[39m256\u001b[39m,\u001b[39m3\u001b[39m,\u001b[39m256\u001b[39m,\u001b[39m256\u001b[39m))\u001b[39m.\u001b[39mcuda()\n",
      "File \u001b[1;32mc:\\dev\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:749\u001b[0m, in \u001b[0;36mModule.cuda\u001b[1;34m(self, device)\u001b[0m\n\u001b[0;32m    732\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcuda\u001b[39m(\u001b[39mself\u001b[39m: T, device: Optional[Union[\u001b[39mint\u001b[39m, device]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[0;32m    733\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[0;32m    734\u001b[0m \n\u001b[0;32m    735\u001b[0m \u001b[39m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[39m        Module: self\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 749\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(\u001b[39mlambda\u001b[39;49;00m t: t\u001b[39m.\u001b[39;49mcuda(device))\n",
      "File \u001b[1;32mc:\\dev\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:641\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    639\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[0;32m    640\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 641\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    643\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    644\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    645\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    646\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    651\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    652\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\dev\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:641\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    639\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[0;32m    640\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 641\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    643\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    644\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    645\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    646\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    651\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    652\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\dev\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:664\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    660\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    661\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    662\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    663\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> 664\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[0;32m    665\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    666\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[1;32mc:\\dev\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:749\u001b[0m, in \u001b[0;36mModule.cuda.<locals>.<lambda>\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    732\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcuda\u001b[39m(\u001b[39mself\u001b[39m: T, device: Optional[Union[\u001b[39mint\u001b[39m, device]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[0;32m    733\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[0;32m    734\u001b[0m \n\u001b[0;32m    735\u001b[0m \u001b[39m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[39m        Module: self\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 749\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply(\u001b[39mlambda\u001b[39;00m t: t\u001b[39m.\u001b[39;49mcuda(device))\n",
      "File \u001b[1;32mc:\\dev\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch\\cuda\\__init__.py:221\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    217\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    218\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    219\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmultiprocessing, you must use the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mspawn\u001b[39m\u001b[39m'\u001b[39m\u001b[39m start method\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    220\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(torch\u001b[39m.\u001b[39m_C, \u001b[39m'\u001b[39m\u001b[39m_cuda_getDeviceCount\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m--> 221\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTorch not compiled with CUDA enabled\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    222\u001b[0m \u001b[39mif\u001b[39;00m _cudart \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    223\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[0;32m    224\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "net =net.cuda()\n",
    "tensortensor = t.randn((256,3,256,256)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec 13 17:05:30 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 527.56       Driver Version: 527.56       CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| 30%   36C    P2    28W / 200W |   1706MiB /  8192MiB |     15%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A       916    C+G   ...perience\\NVIDIA Share.exe    N/A      |\n",
      "|    0   N/A  N/A      1896    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A      2308    C+G   ...n1h2txyewy\\SearchHost.exe    N/A      |\n",
      "|    0   N/A  N/A      5168    C+G   ...icrosoft VS Code\\Code.exe    N/A      |\n",
      "|    0   N/A  N/A      7028      C   ...3\\envs\\pytorch\\python.exe    N/A      |\n",
      "|    0   N/A  N/A      7920    C+G   ...oftware\\zotero\\zotero.exe    N/A      |\n",
      "|    0   N/A  N/A     11704    C+G   ...2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     12524    C+G   ...perience\\NVIDIA Share.exe    N/A      |\n",
      "|    0   N/A  N/A     14636    C+G   ...d\\runtime\\WeChatAppEx.exe    N/A      |\n",
      "|    0   N/A  N/A     15576    C+G   ...tracted\\WechatBrowser.exe    N/A      |\n",
      "|    0   N/A  N/A     17796    C+G   ...6YXSAPEQCFR43DA\\DeepL.exe    N/A      |\n",
      "|    0   N/A  N/A     19524    C+G   ...lPanel\\SystemSettings.exe    N/A      |\n",
      "|    0   N/A  N/A     20068    C+G   ...cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "|    0   N/A  N/A     20264    C+G   ...h8wxbdkxb8p\\DCv2\\DCv2.exe    N/A      |\n",
      "|    0   N/A  N/A     21156    C+G   ...ray\\lghub_system_tray.exe    N/A      |\n",
      "|    0   N/A  N/A     21772    C+G   ...ge\\Application\\msedge.exe    N/A      |\n",
      "|    0   N/A  N/A     24944    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A     25264    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     28292    C+G   ...tware\\qqmusic\\QQMusic.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.cpu()\n",
    "tensortensor =tensortensor.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec 13 17:05:30 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 527.56       Driver Version: 527.56       CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| 30%   36C    P2    34W / 200W |   1706MiB /  8192MiB |     12%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A       916    C+G   ...perience\\NVIDIA Share.exe    N/A      |\n",
      "|    0   N/A  N/A      1896    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A      2308    C+G   ...n1h2txyewy\\SearchHost.exe    N/A      |\n",
      "|    0   N/A  N/A      5168    C+G   ...icrosoft VS Code\\Code.exe    N/A      |\n",
      "|    0   N/A  N/A      7028      C   ...3\\envs\\pytorch\\python.exe    N/A      |\n",
      "|    0   N/A  N/A      7920    C+G   ...oftware\\zotero\\zotero.exe    N/A      |\n",
      "|    0   N/A  N/A     11704    C+G   ...2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     12524    C+G   ...perience\\NVIDIA Share.exe    N/A      |\n",
      "|    0   N/A  N/A     14636    C+G   ...d\\runtime\\WeChatAppEx.exe    N/A      |\n",
      "|    0   N/A  N/A     15576    C+G   ...tracted\\WechatBrowser.exe    N/A      |\n",
      "|    0   N/A  N/A     17796    C+G   ...6YXSAPEQCFR43DA\\DeepL.exe    N/A      |\n",
      "|    0   N/A  N/A     19524    C+G   ...lPanel\\SystemSettings.exe    N/A      |\n",
      "|    0   N/A  N/A     20068    C+G   ...cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "|    0   N/A  N/A     20264    C+G   ...h8wxbdkxb8p\\DCv2\\DCv2.exe    N/A      |\n",
      "|    0   N/A  N/A     21156    C+G   ...ray\\lghub_system_tray.exe    N/A      |\n",
      "|    0   N/A  N/A     21772    C+G   ...ge\\Application\\msedge.exe    N/A      |\n",
      "|    0   N/A  N/A     24944    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A     25264    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     28292    C+G   ...tware\\qqmusic\\QQMusic.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec 13 17:05:30 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 527.56       Driver Version: 527.56       CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| 30%   36C    P2    38W / 200W |   1450MiB /  8192MiB |      4%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A       916    C+G   ...perience\\NVIDIA Share.exe    N/A      |\n",
      "|    0   N/A  N/A      1896    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A      2308    C+G   ...n1h2txyewy\\SearchHost.exe    N/A      |\n",
      "|    0   N/A  N/A      5168    C+G   ...icrosoft VS Code\\Code.exe    N/A      |\n",
      "|    0   N/A  N/A      7028      C   ...3\\envs\\pytorch\\python.exe    N/A      |\n",
      "|    0   N/A  N/A      7920    C+G   ...oftware\\zotero\\zotero.exe    N/A      |\n",
      "|    0   N/A  N/A     11704    C+G   ...2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     12524    C+G   ...perience\\NVIDIA Share.exe    N/A      |\n",
      "|    0   N/A  N/A     14636    C+G   ...d\\runtime\\WeChatAppEx.exe    N/A      |\n",
      "|    0   N/A  N/A     15576    C+G   ...tracted\\WechatBrowser.exe    N/A      |\n",
      "|    0   N/A  N/A     17796    C+G   ...6YXSAPEQCFR43DA\\DeepL.exe    N/A      |\n",
      "|    0   N/A  N/A     19524    C+G   ...lPanel\\SystemSettings.exe    N/A      |\n",
      "|    0   N/A  N/A     20068    C+G   ...cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "|    0   N/A  N/A     20264    C+G   ...h8wxbdkxb8p\\DCv2\\DCv2.exe    N/A      |\n",
      "|    0   N/A  N/A     21156    C+G   ...ray\\lghub_system_tray.exe    N/A      |\n",
      "|    0   N/A  N/A     21772    C+G   ...ge\\Application\\msedge.exe    N/A      |\n",
      "|    0   N/A  N/A     24944    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A     25264    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     28292    C+G   ...tware\\qqmusic\\QQMusic.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.67204284667969"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import get_model_size\n",
    "get_model_size(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= [(\"a\",1),(\"b\",2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1, 'b': 2}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mlist\u001b[39m(net\u001b[39m.\u001b[39mparameters())[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'net' is not defined"
     ]
    }
   ],
   "source": [
    "list(net.parameters())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1., 1.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 1., 0., 1.],\n",
       "       [1., 0., 1., 0.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "seed = 0\n",
    "num_clients = 4\n",
    "np.random.seed(seed)\n",
    "mat = np.random.randn(num_clients, num_clients)\n",
    "mat[mat<=0]=0\n",
    "mat[mat>0]=1\n",
    "mat_tri = np.triu(mat)\n",
    "mat_tri-=np.diag(np.diagonal(mat_tri))\n",
    "mat_tri+mat_tri.T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3de46a193a0b9e5b3bc67286d0c342e53305376cf8bea956d6cd171e456c1d38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
